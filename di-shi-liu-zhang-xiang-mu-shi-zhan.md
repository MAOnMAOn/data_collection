第十六章 项目实战

最近(2017年10月)，接手了一个电商网站关键字爬虫，简单详情如下：

任务概况：
目标站点：淘宝，天猫，1688，京东，1号店，苏宁
总数据量需求：内部初定 100 万，(当然，甲方希望多多益善)
目标关键字：约300个
给定时间：2 周
爬取字段：价格，销量(评价)，标题，url，地区等

现有资源：
服务器 4 台，其中３台为内网拨号宽带
人力：爬虫模块为1人，数据处理模块1~3人

任务分析：
电商网站，比如阿里系相关站点，反爬措施相对较强。如：
1. 目标爬取字段之中的价格，销量数据都需要进行 js 渲染。
2. 网站对单位时间内请求量较大的 ip，会强制跳转到登录页面。
3. 网站部分接口进行了加密处理，相关信息需要进行验证，如 csrf 鉴权。
......

因此，对于部分电商站点，采集百万级别的数据，有时候并不轻松：
1. 寻找可用的接口，没有接口或者反爬手段较为严厉时，还需要通过模拟浏览器等备用方案，进行数据获取。
2. 优先使用 ADSL 代理(网上的免费代理，以及部分知名度较高的付费代理，可能已经被目标站点列入黑名单)。
3. 必要时，通过建立 cooie 池等方式，模拟用户行为。
4. 对爬取速度进行适度控制，适当减少单位时间，单台主机的并发数。
5. 为保证及时完成任务，可以进行分布式部署管理。

### 1. 工作时间估算

从2周后开始倒推:初步设定工作日为10日：
* 业务部门对数据进行后续分析处理：2个工作日
* 爬虫数据的清洗整理，分类汇总：1个工作日

此时，留给爬虫的工作日仅余７日。

*** 数据存储 ***
各个网站爬虫，可以共用相同的数据存储(数据库，存储字段)
数据存储(利用mongodb)模块编写调试以及数据库建表不超过 4 小时。

*** 数据解析 ***
4个网站都有接口,1个网站移动端接口需要 post 验证，最后一个需要进行 dom 解析，4个网站解析部分代码不超过 6 小时，dom 调试解析 不超过 5 小时，post 验证接口相对繁琐，转而解析 jsonp 文件，不超过 4 小时

*** 网络请求 ***
设置网络代理，使用 ADSL 拨号，代码编写测试为 2 小时
设置网站请求头，总计 1　小时
使用生产者/消费者模式进行 Url 管理：3 小时

*** 部署监控 ***
使用局域网多主机 + 容器技术 进行部署
dockerfile + dockercompose.yml 文件编写(构建 scrapy、Prometheus、grafana容器) 计 6 小时
日志使用 logging 计 2 小时

*** 错误处理插件 ***
进行网页状态码，网络超时，页面解析为空等错误处理模块编写，不超过 5 小时

*** 备用方案　***
准备强反爬网站的 selenium 爬虫代码，不超过 8 小时

*** 爬取策略设计 ***
设计爬取策略，不超过3小时

*** 爬虫爬取时间估算 ***
爬虫使用并行爬取，本着先易后难原则，先编写若反爬网站代码，保证基础数据获取，在进行强反爬网站采集。一般而言，爬取时间，大多是结合爬取速度以及网站反爬手段进行动态调整，实际工作之中，事前的时间估算与其他部分比较是准确率最低的。

这样，我们就完成了简单的时间分配估算。







