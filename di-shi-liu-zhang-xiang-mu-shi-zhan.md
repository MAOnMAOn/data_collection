# 第十六章 项目实战

本章，我们将通过一个电商网站关键字爬虫，进一步学习爬虫相关知识技能。下面就让我们一起来感受一下吧。

_**任务概况**_  
目标站点：淘宝，天猫，1688，京东，1号店，苏宁  
总数据量需求：内部初定 100 万，\(当然，甲方希望多多益善\)  
目标关键字：约300个  
给定时间：2 周  
爬取字段：价格，销量\(评价\)，标题，url，地区等

_**现有资源**_  
服务器 4 台，其中 3 台为内网拨号宽带  
人力：爬虫模块暂定为1人，数据处理模块1~3人

### 1. 简单分析

电商网站，比如阿里系相关站点，反爬措施相对较强。如：  
1. 目标爬取字段之中的价格，销量数据都需要进行 js 渲染。  
2. 网站对单位时间内请求量较大的 ip，会强制跳转到登录页面。  
3. 网站部分接口进行了加密处理，相关信息需要进行验证，如 csrf 鉴权。  
......

因此，对于部分电商站点，采集百万级别的数据，有时并不轻松，我们需要：  
1. 寻找可用的接口，没有接口或者反爬手段较为严厉时，还需要通过模拟浏览器等备用方案，进行数据获取。  
2. 优先使用 ADSL 代理\(网上的免费代理，以及部分知名度较高的付费代理，可能已经被目标站点列入黑名单\)。  
3. 必要时，通过建立 cooie 池等方式，模拟用户行为。  
4. 对爬取速度进行适度控制，适当减少单位时间，单台主机的并发数。  
5. 为保证及时完成任务，可以进行分布式部署管理。  
6. 爬虫需要足够健壮，比如具备断点续爬，消息推送，日志记录，动态拓展等相关功能

### 2. 工作时间估算

从2周后开始倒推:初步设定工作日为10日：

* 业务部门对数据进行后续分析处理：2个工作日
* 爬虫数据的清洗整理，分类汇总：1个工作日

此时，留给爬虫的工作日仅余７日。

_** 数据存储 **_  
各个网站爬虫，可以共用相同的数据存储\(数据库，存储字段\)  
数据存储\(利用mongodb\)模块编写调试以及数据库建表不超过 4 小时。

_** 数据解析 **_  
4个网站都有接口,1个网站移动端接口需要 post 验证，最后一个需要进行 dom 解析，4个网站解析部分代码不超过 6 小时，dom 调试解析 不超过 5 小时，post 验证接口相对繁琐，转而解析 jsonp 文件，不超过 4 小时

_** 网络请求 **_  
设置网络代理，使用 ADSL 拨号，代码编写测试为 2 小时  
设置网站请求头，总计 1　小时  
使用生产者/消费者模式进行 Url 管理：3 小时

_** 部署监控 **_  
使用局域网多主机 + 容器技术 进行部署  
dockerfile + dockercompose.yml 文件编写\(构建 scrapy、Prometheus、grafana容器\) 计 6 小时  
日志使用 logging 计 2 小时

_** 错误处理插件 **_  
进行网页状态码，网络超时，页面解析为空等错误处理模块编写，不超过 5 小时

_** 备用方案　**_  
准备强反爬网站的 selenium 爬虫代码，不超过 8 小时

_** 爬取策略设计 **_  
设计爬取策略，不超过3小时

_** 爬虫爬取时间估算 **_  
爬虫使用并行爬取，本着先易后难原则，先编写弱反爬网站代码，保证基础数据获取，在进行强反爬网站采集。一般而言，爬取时间，大多是结合爬取速度以及网站反爬手段进行动态调整，实际工作之中，事前的时间估算与其他部分比较是准确率最低的。

这样，我们就完成了简单的时间分配估算。

