## 1.8 部署相关库的安装

如果想要大规模抓取数据，进一步提升数据抓取效率，那么一定会用到分布式爬虫，对于分布式爬虫来说，我们需要多台主机，每台主机多个爬虫任务，但是源代码其实只有一份。那么我们需要做的就是将一份代码同时部署到多台主机上来协同运行，那么怎么去部署就又是一个值得思考的问题。

对于 Scrapy 来说，它有一个扩展组件叫做 Scrapyd，我们只需要安装 Scrapyd 即可远程管理 Scrapy 任务，包括部署源码、启动任务、监听任务等操作。另外还有 ScrapydClient 和 ScrapydAPI 来帮助我们更方便地完成部署和监听操作。

此外我们还可以通过 Docker 集群部署，我们只需要编写 Dockerfile ,将爬虫制作为 Docker 镜像，只要主机安装了 Docker，就可以直接运行爬虫，而无需再去担心环境配置、版本问题。