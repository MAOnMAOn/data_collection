# 第四章 数据采集策略

在进行网络数据采集之前，我们还要进行数据采集策略的制定，如何制定数据采集策略，还要结合目标站点的特征、数据采集需求以自身采集资源预算进行分析。

***目标站点特征***
1. 单纯静态页面，反爬弱
2. 可以获取 json 输出数据
3. 需要登录才能访问数据
4. 其他

***数据采集需求***
1. 计划采集的数据规模
2. 数据存储的结构类型
3. 其他

***采集的预算资源***
1. 现有机器的数量与性能
2. 人力成本
3. 可获取的资金，技术，人力支持等等

*** 工作(时间、任务)估算 ***
1. 普通站点，小批量采集
2. 普通站点，大批量采集
3. 强反爬网站，小规模采集
4. 强反爬网站，大规模采集

所以，针对具体问题进行具体分析，特别是大型爬虫项目，合理制定数据采集策略是十分重要的。下面，我们以工作时间的估算为例，进行简要说明。

### 1. 工作时间估算
最近(2017年10月)，项目经理分发了一项任务，针对国内主流电商网站(6家)，开展一次关键字爬虫，时间初步限定为2周。以下是个人初步分析思路(不同的项目可能会有所不同，而且同一个项目也会在实际执行中发生变化)。

从2周后开始倒推:初步设定工作日为10日：
* 业务部门对数据进行后续分析处理：2个工作日
* 爬虫数据的清洗整理，分类汇总：1个工作日

此时，留给爬虫的工作日仅余７日。

*** 数据存储 ***
各个网站爬虫，可以共用相同的数据存储(数据库，存储字段)
数据存储(利用mongodb)模块编写调试以及数据库建表不超过 4 小时。

*** 数据解析 ***
4个网站都有接口,1个网站移动端接口需要 post 验证，最后一个需要进行 dom 解析，4个网站解析部分代码不超过 6 小时，dom 调试解析 不超过 5 小时，post 验证接口相对繁琐，转而解析 jsonp 文件，不超过 4 小时

*** 网络请求 ***
设置网络代理，使用 ADSL 拨号，代码编写测试为 2 小时
设置网站请求头，总计 1　小时
使用生产者/消费者模式进行 Url 管理：3 小时

*** 部署监控 ***
使用局域网多主机 + 容器技术 进行部署
dockerfile + dockercompose.yml 文件编写(构建 scrapy、Prometheus、grafana容器) 计 6 小时
日志使用 logging 计 2 小时

*** 错误处理插件 ***
进行网页状态码，网络超时，页面解析为空等错误处理模块编写，不超过 5 小时

*** 备用方案　***
准备强反爬网站的 selenium 爬虫代码，不超过 8 小时

*** 爬取策略设计 ***
设计爬取策略，不超过3小时

*** 爬虫爬取时间估算 ***
爬虫使用并行爬取，本着先易后难原则，先编写若反爬网站代码，保证基础数据获取，在进行强反爬网站采集。一般而言，爬取时间，大多是结合爬取速度以及网站反爬手段进行动态调整，实际工作之中，事前的时间估算与其他部分比较是准确率最低的。

这样，我们就完成了简单的时间分配估算。