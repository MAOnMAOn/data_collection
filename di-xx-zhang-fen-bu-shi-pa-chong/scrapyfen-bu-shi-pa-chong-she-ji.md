## scrapy 分布式设计

要想拥有一个健壮的爬虫，首先要进行爬虫的设计，这也就是入门常说的'工欲善其事必先利其器'。本节我们开始分布式爬虫设计的介绍，下面让我们一起感受一下吧。

### 1. scrapy 单主机爬虫

在进行分布式爬虫的设计之前单主机架构之中，Requests 队列由每台主机分别维护，而调度器从队列中调度 Request 进行请求，在 scrapy 框架的基础上，我们可以很快设计出一个相对健壮的爬虫：

![](/assets/单主机爬虫2.png)

但是上述设计，在面对大规模数据爬取，进行分布式部署时就多少有些力不从心了，在多主机进程之间相互独立分割的情况下，很容易发生重复请求与爬取的情况，既加大了目标站点的负载，又会给后期工作增加过多的损耗。所以在分布式爬虫之中，就需要进行必要的改良，比如使用消息队列机制。

### 2. Master-Slave 初步设计

编写分布式爬虫，首先要做到队列的统一调度，请求的统一去重，同时通过消息队列机制实现程序的断点续爬。

![](/assets/截图_2017-11-22_11-05-31.png)

使用 scrapy-redis 默认配置，我们可以简单地实现队列统一调度，请求统一去重，以及断点续爬。

但简单地使用默认配置，还会有许多一些问题，比如 redis 占用过多的内存，增加 master 主机的负载；同时，过多的信息交互也影响网络 I/O，降低爬虫运行效率，最后，系统拓展性较差。

### 3. Master-Slave 与生产者/消费者模式

通过使用 redis 列表，我们可以很方便地通过 scrapy-redis 进行爬取调度，在 Master 端生成任务，任务可以是请求，链接或者是 ID。Master 负责生成任务，并把任务去重复、加入待爬取队列；Slave 只需要获取任务即可。

![](/assets/fbuspacjiagou.png)

### 4. 其他

#### \(1\) 监控

在 scrapy 之中，我们可以通过改写拓展模块来进行自定义监控，也可以通过一些第三方开源监控工具进行一些可视化监控\(爬取速度、系统负载、日志分析\)。相关具体细节，大家可以参考先前介绍的相关内容。

#### \(2\) 部署

当爬虫写好以后，一般还要把代码从本机部署到服务器环境之中。对于 scrapy 爬虫，我们可以使用官方推荐使用的 scrapyd 进行项目的打包部署。当然，我们还可以结合容器技术，进一步发掘现有硬件资源，提升硬件资源的使用效率。

比如，使用 docker-compose 进行项目的部署管理，我们可以很方便地在单主机上开启多个 scrapy 实例，进一步利用多核 cpu 资源。

当然，我们还可以引入 docker swarm / K8S 进行容器编排。swarm \(K8S\)集群可以像单个系统那样工作，并提供高可用、负载均衡与并行处理。

如果我们部署应用和服务是选择的是多个独立的服务器而非\(容器\)集群，资源的整体利用率很难达到最优，因为我们无法提前只知道如何分布应用才可以达到资源利用的最大化。

实现集群化以后，我们不必再考虑一个个的服务器，而是可以把集群看成一个整体。部署项目，只要考虑有多少 CPU 与内存，而不是考虑目标服务器的内存与 CPU。不必过分关心应用会被部署在哪里，而是关心运行应用需要什么资源，然后部署到集群，集群管理程序可以搞定相关细节。

